<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
  <link href="https://getbootstrap.com/docs/5.3/assets/css/docs.css" rel="stylesheet">
  <title>Krishna Teja Chitty-Venkata</title>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
  <meta name="google-site-verification" content="bvU_3gV46p13msPzzG_mKlpNbPjmUh_5VrMPJbGs9ls" />
</head>

<body class="p-3 m-0 border-0 bd-example m-0 border-0">

  <nav class="navbar navbar-expand-lg navbar-dark bg-dark static-top">
    <div class="container">

      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent"
        aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav me-auto mb-2 mb-lg-0">
            
<li class="nav-item">
<a class="nav-link" href="index.html">Home</a>
</li>
<li class="nav-item">
  <a class="nav-link active" aria-current "page" href ="industry.html ">Professional Experience</a>
 </li>
<li class="nav-item">
  <a class="nav-link" href="research.html">Research Experience</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="resume.html">Curriculum Vitae</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="fun.html">Gallery</a>
</li>
            
        </ul>
      </div>
    </div>
  </nav>
    
<p>&nbsp;</p>   
<hr>

    
<h4><u>Work Experience</u></h4>

<ul>
<li><strong>Argonne National Laboratory, Lemont, IL, USA</strong>
<ul>

<li>Postdoctoral Researcher (August 2023 - Current) in the AI/ML team of Argonne's Supercomputing facility</li>
<li>Research at the intersection of Systems and Deep Learning; mainly on optimizing Inference and finetuning of LLMs (Deep Learning models in general)</li>
<li>Collaborating with scientists and engineers from Nvidia, Intel, AMD, SambaNova, Cerebras, Groq, Graphcore and Habana</li>
<li>Involving in organizing workshops, tutuorials and helping users of the computing facility to succesfully run their code on different systems</li>
</ul>
</li>
 
<br>
    
<li><strong>Argonne National Laboratory, Lemont, IL, USA (Virtual)</strong>
<ul>
<li>Research Intern (September 2021 - November 2021) in the AI/ML team of Argonne's Supercomputing facility</li>
<li>Worked on a project at the intersection of Pruning, Quantization and Neual Architecture Search</li>
<li>Published my research findings in <a href="https://www.hpdc.org/2022/"target="_blank">HPDC 2022 Conference</a></li>
</ul>
</li>
    
    
<br>    
<li><strong>Intel Corporation, Santa Clara, CA, USA (Virtual)</strong>
<ul>
<li>Deep Learning Research Scientist Intern (June 2020 - December 2020) in the <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/graphics-research/overview.html#researchers"target="_blank">Graphics Processing Research Lab</a></li>     

<li>Designed Convolutional Neural Network model optimization strategies for Image Super Resolution and Denoising applications 
<li>Designed Neural Architecture Search methods for Mixed Precision Quantization and efficient hardware-aware neural networks for Graphics related problems using Unet model
<li>Published my research findings in <a href="https://www.2021.ieeeicip.org/www.2021.ieeeicip.org/default.html"target="_blank">ICIP 2021 Conference</a></li>
</ul>
</li>    
    
    
<br>    
<li><strong>Advanced Micro Devices (AMD), Austin, TX, USA</strong>
<ul>
<li>Worked in the MIGraphX team  (May 2019 - August 2019)</li>
<li>Developed Post Training Quantization (PTQ) methods to reduce the CNN weights from FP32 to Int8 precision.</li>
<li>Implemented the quantization algorithms and analysis on Vgg16, ResNet50, InceptionV3, Xception benchmark, resulting in negligible accuracy loss on Imagenet</li>    
</ul>
</li>    


    
<br>    
<li><strong>Research Centre Imarat, Defence R&amp;D Organization, Hyderabad, India</strong>
<ul>
<li>Undergraduate Technical Intern (May 2016 - June 2016)</li>
</ul>
</li>    

    
<br>    
<li><strong>Bharat Dynamics Limited (BDL), Hyderabad, India</strong>
<ul>
<li>Undergraduate Technical Intern (December 2015)</li>
</ul>
</li>    
    
    
</ul>

    

<p>&nbsp;</p>
<hr>

    
    
    

    
<h4><u>Academic Experience</u></h4>
    
    
    
    
<ul>

    
<li><strong>Graduate Research Assistant</strong>
<ul>
<li>Supervisor: Dr. Arun K. Somani</li>
</ul>
    
    




    
    
    
<li><strong>Graduate Teaching Assistant</strong>
<ul>
<li>Teaching Assistant for the following courses:  
<ul>
<li>Digital Logic Design (Undergraduate Course) for Fall 2017 and Spring 2018
<li>Fault Tolerant Computing Systems (Graduate Course) for Spring 2020 and Spring 2022
</ul>
    
    
<li>Responsibilities included:
<ul>    
<li>Conducting weekly lab sessions to assist students in writing code using Verilog HDL.
<li>Guiding students on their final course projects, specifically focused on deploying applications on FPGA.
<li>Holding office hours to provide one-on-one support and address students' queries effectively.
<li>Evaluating homeworks, lab reports, and exams, while offering constructive feedback to enhance learning outcomes.    
</ul>    
    
    
    
</ul>

    
<li><strong>Graduate Courses</strong>

    
    
<ul>
<li>
<strong>Machine Learning/Stats</strong>: Advance Design and Analysis of Algorithms, Deep Learning: Theory and Practice, Machine Learning, Probabilistic Methods, Statistical Methods for Machine Learning, Statistics Theory for Research
</li>
</ul>
    
    
<ul>
<li>
<strong>Systems</strong>: Applications of Parallel Computers (CS267- Berkeley; CprE 594 at ISU), Computer System Architecture, Fault Tolerant Computing Systems, High Performance Communication Networks, Real Time Systems
</li>
</ul>
    
    
    
    
<!--     
    
<ul>
<li>
Advance Design and Analysis of Algorithms (COM S 511), Applications of Parallel Computers (CS267- Berkeley; CprE 594 at ISU), Computer System Architecture (CprE 581), Deep Learning: Theory and Practice (EE525x), Fault Tolerant Computing Systems (CprE 545), High Performance Communication Networks (CprE 541), Machine Learning (COMS 573), Probabilistic Methods for Computer Engineering (CprE 528), Real Time Systems (CprE 558), Statistical Methods for Machine Learning (EE 520), Statistics Theory for Research (Stat 447)
</li>
</ul> -->

    
    
</ul>    
    
<p>&nbsp;</p>   
<hr>
    
    
    
    
    
<h4><u>Achievements</u></h4>
<ul>
    
    
    
<li><strong>Research Excellence Award</strong> by Iowa State University Graduate School, Fall 2022 [<a href="files/Research_Excellence_Certificate_2.pdf"target="_blank">Certificate</a>] [<a href="files/Research_Excellence_Certificate_1.pdf"target="_blank">Letter from President</a>] </li>
<li><strong>Research Award</strong> by Graduate and Professional Student Senate (GPSS) society at Iowa State University,
Spring 2023 [<a href="files/GPSS_Award.pdf"target="_blank">Certificate</a>]</li>
<li>Selected for <strong>Oxford Machine Learning Summer school</strong> 2022 (<a href="https://www.oxfordml.school/2022"target="_blank">OxML</a>) in ML for Health and ML for Finance tracks [<a href="files/OxML_2022_Certificate.pdf"target="_blank">Certificate</a>] (Acceptance Rate &lt; 10&percnt;)</li>    
    
<li>Our survey paper “Neural Architecture Search Survey: A Hardware Perspective,” has been identified as one
of the must-read AI papers in 2022 by a group of industry experts [<a href="https://blog.re-work.co/the-top-17-must-read-ai-papers-in-2022/"target="_blank">URL</a>]</li>    
    
<!-- <li>HPDC 2022 Student Travel Grand Award</li>     -->
    
    
    
    
    
     
     
    
</ul>

<p>&nbsp;</p>   
<hr>

<h4><u>Service</u></h4>
<ul>
<li><strong>Conferences:</strong> HiPC 2025, DCAA'23 (AAAI), AutoML 2023 (3x)</li>
<li><strong>Journals:</strong> IEEE TNNLS, PeerJ Computer Science (3x), Elsevier Neural Networks (3x), IEEE TNNLS, ACM CSUR, Machine Learning with Applications, Intelligent Automation and Soft Computing, IEEE TCAD, MDPI Applied Sciences (2x)</li>
</ul>
    
    
    
<p>&nbsp;</p>   
<hr>

<h4><u>Talks/Presentations/Teaching</u></h4>
    <ul>
        <li>Invited Talk, GE Vernova </li>
            <ul>
              <li>Inference Optimizations of Large Language Models 
                </li>
            </ul>
        
        <li>Paper Presentation, Workshop on Performance Modeling, Benchmarking and Simulation of HPC Systems (PMBS), Supercomputing 2024 
        </li>
            <ul>
              <li>Inference Optimizations of Large Language Models 
                </li>
            </ul>
        
        <li>Speaker, ALCF HPC Hands-on Workshop 2024</li>
            <ul>
              <li>Inference Optimizations of Large Language Models</li>
            </ul>
        
        <li>Poster Presentation, Monterey Data Conference 2024</li>
            <ul>
              <li>Inference Optimizations of Large Language Models</li>
            </ul>
        
        
        <li>Paper Presentation, International European Conference on Parallel and Distributed Computing (EuroPar 2024)</li>
            <ul>
              <li>Inference Optimizations of Large Language Models</li>
            </ul>
        
        
        <li>Postdoc Candidate Talks at Argonne and Oak Ridge National Labs</li>
            <ul>
              <li>Inference Optimizations of Large Language Models</li>
            </ul>
        
        <li>Invited Alumni Talk, Osmania University, Hyderabad (virtual) </li>
            <ul>
              <li>Inference Optimizations of Large Language Models</li>
            </ul>
        
        
        <li>Paper Presentation, International Symposium on High-Performance Parallel and Distributed Computing</li>
            <ul>
            </ul>
        
        
        <li>Paper and Poster Presentation, 2021 IEEE International Conference on Image Processing (ICIP) (virtual)</li>
            <ul>
            </ul>
        
        <li>Paper Presentation, 2021 IEEE 32nd International Conference on Application-specific Systems, Architectures and Processors (virtual)</li>
            <ul>
            </ul>
        
        <li>Paper Presentation, 2020 IEEE 22nd International Conference on High Performance Computing and Communications (virtual)</li>
            <ul>
            </ul>
        
        <li>Paper Presentation, 2020 IEEE 31st International Conference on Application-specific Systems, Architectures and Processors (virtual)</li>
            <ul>
            </ul>
        
        <li>Poster Presentation, 2019 IEEE 30th International Conference on Application-specific Systems, Architectures and Processors (ASAP)</li>
            <ul>
            </ul>
<!--         
        
        <li>Graduate Seminar, Iowa State University 
        </li>
            <ul>
              <li> [<a href="https://ai3dg.github.io/">Slides</a>]</li>
            </ul>
        
        
        <li>PhD Defense [<a href="https://ai3dg.github.io/">URL</a>]</li>
            <ul>
              <li> [<a href="https://ai3dg.github.io/">Slides</a>]</li>
            </ul>
         -->

    </ul>

<p>&nbsp;</p>   
<hr>





    
<h4><u>Skills and Technical Experience</u></h4>    
    
<ul>

    
    <li><strong>Generic:</strong></li>    
    <ul>
    <li><strong>Programming Languages:</strong></li>
        <ul>
        <li><strong>Strong:</strong> C, C++, Python, CUDA</li>    
        <li><strong>Working Knowledge:</strong> OpenMP, MPI, Matlab</li>
            
            
        </ul>
    <li><strong>Others:</strong> Git, HTML, LaTeX, shell scripting</li>    
    </ul>
    
    
    
    <li><strong>Machine Learning:</strong></li>    
    <ul>
    <li><strong>Frameworks:</strong></li>
        <ul>
            <li><strong>Primary:</strong> PyTorch, Tensorflow, Keras</li>    
        <li><strong>Training/Finetuning:</strong> NeMo, NeMo-ALigner, Deepspeed-Chat</li>
        <li><strong>Inference:</strong> vLLM, TensorRT-LLM, llama.cpp, Deepspeed-MII</li>    
        </ul>
        
    <li><strong>Models:</strong></li>    
    
        <ul>
        <li><strong>CNNs:</strong> AlexNet, ResNet</li>    
        <li><strong>ViTs:</strong> ViT</li>    
        <li><strong>LLMs:</strong> LLaMA, Mistral, Qwen, Bloom, OPT, Falcon</li>    
        <li><strong>VLMs:</strong> LLaMA-3.2-11B, LLaVA, Pixtral </li>    
        </ul>
    
    </ul>
    
    
    
    
    <li><strong>Hardware:</strong></li>    
    <ul>
    <li><strong>Platforms:</strong></li>    
    
    <ul>
    <li><strong>GPUs:</strong> Nvidia (V100, Turing, A100, H100, GH200), AMD (MI250) and Intel (Max 1550)</li>    
    <li><strong>AI Accelerators:</strong> Cerebras CS-2, SambaNova SN40L, Groq LPU, Graphcore BowPod64, Habana Gaudi2</li>    
    </ul>    
        
    <li><strong>HPC/Supercomputers:</strong></li> 
        
        <ul>
        <li><strong>Argonne Leadership Computing Facility:</strong> Aurora, Polaris, Sophia (previously ThetaGPU) and JLSE</li>    
        <li><strong>Iowa State University:</strong> Nova and Condo</li>    
        </ul>    
        
    <li><strong>Hardware Simulators:</strong> Scale-sim, Gem5</li>    
    </ul>

    
</ul>    
    

    
<!-- <ul>
<li><strong>Programming Languages:</strong> C, C++, Python</li>
<li><strong>ML Frameworks:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>Hardware Platforms:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>HPC/Supercomputers:</strong> ALCF: Polaris, Aurora, Sophia and JLSE, ISU: Nova, Condo </li>
<li><strong>CNN Models:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>ViT Models:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>LLMs:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>VLMs:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>Datasets:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>LLM Frameworks:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
<li><strong>Others:</strong> PyTorch, Tensorflow, Keras, Scikit-learn</li>
</ul>
     -->
    
    
    
<p>&nbsp;</p>   
<hr>
    
<h4><u>Professional Network</u></h4>    

<ul>
<li><strong>Mentors</strong>

<ul>
<li>Argonne National Laboratory: Murali Emani, Venkatram Vishwanath, Kevin Harms
<li>Iowa State University: 
<ul>
<li>PhD Supervisor: Arun K. Somani
<li>PhD Dissertation Committee: Akhilesh Tyagi, Henry Duwe, David Fernandez-Baca, Vivekananda Roy
</ul>
<li>External: Sparsh Mittal (IIT Roorkee), Sreeni Kothandaraman (Intel), Mike Vermeulen (AMD)  
</ul>

    
<li><strong>Collaborators/Teammates</strong>
<ul>
<li>Argonne National Laboratory: Bogdan Nicolae, Siddhisanket Raskar, Bharat Kale, Farah Ferdaus, Aditya Tanikanti, Ken Raffenetti, Varuni Sastry
<li>Iowa State University: Shreyas Bangalore Vijayakumar, Yiming Bian
<li>External: Jie Ye (IIT Chicago), Sanjif Shanmugavelu (Groq), Sylvia Howland (Cerebras), Darshan Gandhi (SambaNova)  
</ul>

<li><strong>Mentees</strong>
<ul>
<li>Burak Gulhan (Penn State), Kanishk Arya (MIT-WPU, Pune) </li>
</ul>
    

        
    
    
    
<p>&nbsp;</p>   
<hr>
    
    
    
  <br>

  <p hidden><a href="https://clustrmaps.com/site/1bx3z" title="Visit tracker"><img
        src="//www.clustrmaps.com/map_v2.png?d=SqXwaq_frK5Sfzq0mXTKs3sZMvyrsDy_IezSBgT1oEo&cl=ffffff" /></a></p>

</body>

</html>
